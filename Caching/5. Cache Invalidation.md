# Cache Invalidation

## Definition

**Cache invalidation** is the process of ensuring that data stored in the cache is **correct, fresh, and consistent** with the underlying database.

Whenever the original data changes in the database, the corresponding cache entry must be:

* updated
* removed
* or marked as stale

Failure to properly invalidate cache leads to **serving stale or incorrect data to users**. This is why cache invalidation is famously referred to as:

> “One of the two hard problems in computer science:
> cache invalidation, naming things, and off-by-one errors.”

---

## Why Cache Invalidation Is Hard

Caching itself is easy.
Ensuring **cached data stays correct** is hard.

**It is difficult because**:

* data is stored in **two places** (cache and DB)
* both may be updated at different times
* failures may happen between operations
* distributed systems add network delays and crashes
* concurrent request ordering is unpredictable
* multiple caches or nodes may store the same key

**The core challenge is**:

> Keeping cache and database in sync while maximizing performance.

---

## What Can Go Wrong Without Proper Invalidation

**If invalidation is not handled correctly**:

* users see **stale data**
* analytics and reports show **incorrect results**
* inconsistent application behavior occurs
* race conditions corrupt cache
* debugging becomes very difficult
* financial systems suffer incorrect balances

**Examples**:

* showing old product price after update
* displaying deleted posts in a feed
* serving revoked authentication tokens as valid

---

## Basic Invalidation Approaches

There are three fundamental strategies for cache invalidation.


## 1. Write Invalidate (Delete on Update)

### Idea

When data is updated in the database, **remove the cache entry** instead of updating it.

The next read will:

* miss cache
* fetch updated value from database
* repopulate cache

### Advantages

* simple to implement
* guarantees no stale cache value
* works well with read-through or cache-aside caches

### Disadvantages

* first read after invalidation is slow
* cache thrashing if updates are frequent

---

## 2. Write Update (Update the Cache)

### Idea

Whenever the database is updated, **cache is updated with new value immediately**.

Cache always stores fresh data proactively.

### Advantages

* no stale reads
* no post-update cache miss penalty

### Disadvantages

* higher system complexity
* higher write load on cache
* invalidation must be atomic to avoid inconsistencies

---

## 3. TTL-Based Expiration

### Idea

Each cache entry has a **time-to-live (TTL)**.
After TTL expires, the entry is automatically removed.

The system tolerates temporary staleness until expiry.

### Advantages

* very simple to configure
* avoids permanently stale cache
* removes forgotten keys automatically

### Disadvantages

* stale data may exist during TTL
* popular items expire unnecessarily
* cache thrashing if TTL too small

---

## Common Cache Invalidation Patterns

## 1. Cache-Aside (Lazy Loading)

Application reads:

* check cache first
* if miss → fetch from DB → store in cache

On write:

* update database
* delete cache entry (invalidate)

This is the most widely used strategy.

### Why it is popular

* easy to implement
* works with any database
* avoids stale cache because deleted entry is reloaded on next read

---

## 2. Write-Through

When writing:

* write to cache
* cache writes synchronously to database

Invalidation is unnecessary because both are always in sync.

### Trade-off

* slower writes
* strong consistency

---

## 3. Write-Back (Write-Behind)

When writing:

* update cache
* asynchronously flush to DB later

Invalidation complexity increases because:

* database and cache diverge temporarily
* cache contains newest data, not DB

This improves performance but increases risk.

---

## Consistency Problems in Cache Invalidation

Cache invalidation is closely tied to **consistency models**.

Without careful design, the system may have:

---

### 1. Stale Reads

Cache contains old value after database update.

Example:

* user updates profile picture
* database updated
* cache still has old picture

Result: user keeps seeing old image.

---

### 2. Race Conditions

Concurrent operations cause out-of-order updates.

Example:

* Request A updates name to “Alice”
* Request B updates name to “Bob”
* Cache and DB get updated in different orders

Cache may show Alice while DB shows Bob.

---

### 3. Thundering Herd Problem

A popular key expires or is invalidated:

* thousands of requests miss cache
* all hit database simultaneously

Database may become overloaded.

---

## Why Distributed Caches Make It Even Harder

Single machine cache is simple.
Distributed cache introduces:

* network partitions
* replication delays
* clock skew
* partial failures
* cross-regional propagation latency

Multiple cache nodes may store:

* different versions of same key
* deleted keys that still exist elsewhere

Systems like Redis clusters and CDNs must handle this carefully.

---

## Techniques to Handle Cache Invalidation Safely

### Use short TTL for critical data

Balances freshness and performance.

### Use versioning or timestamps

Store `(value, version)` to detect stale entries.

### Use message queues

Notify cache nodes on data changes.

### Use write ordering guarantees

Avoid race conditions.

### Employ eventual consistency where acceptable

Example: feeds, likes, counts.

---

## Cache Invalidation vs Cache Eviction

These are different concepts.

| Concept                | Meaning                                         |
| ---------------------- | ----------------------------------------------- |
| **Cache Eviction**     | Removing items because cache is full            |
| **Cache Invalidation** | Removing or updating items because data changed |

Eviction is about **space management**.
Invalidation is about **correctness and freshness**.

Both interact but solve different problems.

---

## Summary

- Cache invalidation is crucial for data correctness in caching systems.

- It is challenging due to distributed systems, concurrency, and failure modes.

- Common strategies include write invalidate, write update, and TTL expiration.

- Popular patterns are cache-aside, write-through, and write-back.

- Consistency issues like stale reads and race conditions must be addressed.

- Distributed caches add complexity requiring careful design.

---
